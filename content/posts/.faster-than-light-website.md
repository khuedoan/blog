# Faster than light website

If you click around this website, you may notice it _feels_ oddly fast and
responsive. Even if you're half way around the world away from my server, it
still feels instantanious when you click on any link.

In fact, when you click on a post in the homepage, it's faster than you can
lift your mouse button.

The pages are not actually loaded faster than the speed of light, but it
certainly feel like so. It might look like a static site, but it's not. I will
explain some performance optimizations that I used to make it feel this snappy.

First let's take on the low hanging fruit:

## Act on press

This tweet from the legadary John Camack explain it very well and sparked the
light in my brain to implement it on all of my personal projects from now on.
As someone who play a ton of fast paced first person shooter games, my brain
have been trained to like fast response time. If you swith from `on:click` to
`on:mousedown`, you instantly shave off 100-150ms _perceived_ latency. If a
normal internet connection took 300ms round trip for half the earth distance,
that's basically havelved the latency!

To do this on all links in my website, I overloaded the built in `<a></a>` tag
in my web framework with:

```rs
#[component]
pub fn A() {
    view! {
        <a
            href=path.clone()
            class="contrast"
            on:mousedown={
                let value = navigate.clone();
                move |_| {
                    value(&path, Default::default());
                }
            }
        >
            {post.title}
        </a>
    }
}
```

The `on:mousedown` event still gracefully degrade if the user's browser only
load HTML, it just fallback to the normal `on:click` behaviour.

This can be easily achiveable in most web framework or even vanilla JavaScript,
but there's some more advance stuff that is much easier to do in...

.
.
.

You guessed it!

Rust.

## Isomophic web framework

> [Are we WASM yet?](https://www.arewewebyet.org)
>
> Yes! And it's freaking fast!

I have a function that read markdown content and output HTML, add syntax
highlighting, yadiyadiyada, standard stuff.

But the same function runs on the backend and the frontend, giving the native
app feeling to the site. When you click on a post, the `get_post()` function
get executed and return the post content, if WASM is loaded it will be executed
on the frontend, if not it will run on the server with plain HTML. Again,
graceful degradtion.

But that would still requires a network round trip doesn't it?

Instead of always serving the content from the server, because the web
framework is isomophic, I can statically bake the content as static data in the
binary while writing the same logic:

```rs
// TODO show the old implementation
// build.rs
fn main() {
    let dest_path = Path::new(&out_dir).join("posts_data.rs");

    let entries: Vec<String> = POSTS
        .map(|(date, id)| {
            let markdown = fs::read_to_string(format!("./content/posts/{id}.md"))
            // Truncated
                markdown_to_html(&markdown)
            )
        })

    fs::write(
        dest_path,
        format!(
            "static POSTS: &[(&str, &str, &str, &str)] = &[\n{}\n];",
            entries.join("\n")
        ),
    )
}
```

And inside the logic I can implement the functions to read posts like so:

```rs
include!(concat!(env!("OUT_DIR"), "/posts_data.rs"));

pub fn list_posts() -> Vec<PostMetadata> {
    POSTS
        .iter()
        // Truncated
        .collect()
}

pub fn get_post(path: String) -> Option<(PostMetadata, String)> {
    POSTS
        .iter()
        .filter_map(|(id, title, date, content)| {
            // truncated
        })
        .next()
}
```

And because Leptos is an isomophic framework, the same function can be executed
on the server, or on the client via WASM. If the browser have WASM enabled,
there's zero network roundtrip required, you can even turn off internet after
the initial page load an all posts can still be read.

If the reader doesn't have WASM enabled, it will just load the page and execute
the same function on the server, gracefully degraded. Neat!

There's a catch though, because the content will always be loaded to the
client, it's a bit heavier to load than other pure static sites. But let's be
real here it's still way smaller than other React sites, and WASM is generally
faster to load than JS at the same size. There's still things we can do to reduce the WASM binary size though.

## Reducing the WASM binary size

When I included all markdown files as static string at compile time, and have a
function to convert them to HTML, but that will be slower and increase the
binary size, because we have to include the extra pulldown-cmark and syntec
library, which could increase the size to the Megabytes range.

This could be solved by moving the logic to a `build.rs` file, and render all the content to HTML at build time, removing the need for those library at runtime:

We can also reduce the WAMS binary size even more with some compiler flags:

```toml
[profile.wasm-release]
inherits = "release"
opt-level = 'z'
lto = true
codegen-units = 1
panic = "abort"
```

While it's very fast once the WASM binary is loaded, there's are some other
things that I can do to improve the initial page load, such as adding more
nodes across the globe to my cluster, and better CDN caching. But my self
hosting platform is already over engineered as it is, so I'll leave that for
future weekends.
